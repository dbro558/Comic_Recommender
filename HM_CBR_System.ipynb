{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cedecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install widgetsnbextension\n",
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "!pip install nbopen\n",
    "!pip install import_ipynb\n",
    "!pip install python-dotenv\n",
    "!pip install pandas\n",
    "!pip install psycopg2\n",
    "!pip install ipynb\n",
    "!pip install plotly\n",
    "!pip install nltk\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install jupysec\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4f535-6719-4f23-b571-c7c88c8c00d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Configure logging to write messages with INFO level or higher to a file named \"app.log\" with a timestamp and message format\n",
    "logging.basicConfig(filename='app.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import textwrap\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import zipfile as zf\n",
    "from zipfile import ZipFile\n",
    "from jupysec.rules import Rules\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9ad1f-e235-46b0-9e32-27240732b4c1",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2 import connect\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display as ipydisplay, clear_output, Image, Javascript, HTML, IFrame \n",
    "import import_ipynb\n",
    "import nbopen\n",
    "import base64\n",
    "import string\n",
    "import time\n",
    "#import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce34828",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<style>.container {width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The client, Hideous Mummy Comics, wants to be able to offer comic book recommendations based on a customer's previous purchases. The initial proof of concept of this recommendation system uses the Marvel Comic Books Dataset, found here: https://www.kaggle.com/datasets/deepcontractor/marvel-comic-books. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9969292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dataset was saved to a PostgreSQL database table, \"marvelcomics\". A new sequential column called \"comic_id\" was appended to \"marvelcomics\", and \"customer\" and \"purchase\" tables were added to the database in order to perform dataframe queries involving multiple tables, customer_ids, comic_ids, purchase_ids, purchase_dates, etc. All rows containing null or nan values in the marvelcomics columns \"issue_title\", \"publish_date\", \"issue_description\", \"penciler\", \"writer\", and \"comic_id\" were deleted from the database in pgAdmin 4; deletion of null/nan values in other columns may be required in the future, dependent upon user requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c013d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get security findings\n",
    "#Rules().get_findings() # Commented out for Appmode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94051954-8d89-401f-8118-de12ebd26508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "load_dotenv('.env') # take environment variables from .env\n",
    "\n",
    "db_name = os.getenv(\"DB_NAME\")\n",
    "user_name = os.getenv(\"DB_USERNAME\")\n",
    "host_name = os.getenv(\"DB_PATH\")\n",
    "passwd = os.getenv(\"DB_PASSWORD\")\n",
    "db_port = os.getenv(\"DB_PORT\")\n",
    "\n",
    "conn = psycopg2.connect(host=host_name, dbname=db_name, user=user_name, password=passwd, port=db_port)\n",
    "\n",
    "cursor = conn.cursor()\n",
    "logging.info(\"Connected to database.\")\n",
    "\n",
    "customer_table_query = pd.read_sql_query(\"SELECT cust_id, cust_name, username, user_pass FROM customer\", conn)\n",
    "\n",
    "marvel_comics_table_query = pd.read_sql_query(\"SELECT comic_name, issue_title, publish_date, issue_description, penciler, writer, comic_id FROM marvelcomics\", conn)\n",
    "\n",
    "marvel_comics_query_2 = pd.read_sql_query(\"SELECT issue_title, publish_date, issue_description, penciler, writer, comic_id FROM marvelcomics\", conn) \n",
    "\n",
    "marvel_comics_query_3 = pd.read_sql_query(\"SELECT comic_name, issue_title, publish_date, penciler, writer, comic_id FROM marvelcomics\", conn)\n",
    "\n",
    "purchase_table_query = pd.read_sql_query(\"SELECT purchase_date, cust_id, comic_id FROM purchase\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868a2fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Database tables were then saved to pandas dataframes, using only the necessary columns for each dataframe. Copies of some dataframes are used to preserve the data in the original dataframes for possible future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476cdf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customers DataFrame = df\n",
    "df = pd.DataFrame(customer_table_query, columns=['cust_id', 'cust_name', 'username', 'user_pass'])\n",
    "df.to_csv('customers.csv', index=False)\n",
    "df = pd.read_csv('customers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce30c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marvel Comics DataFrame = df1\n",
    "df1 = pd.DataFrame(marvel_comics_table_query, columns=['comic_name', 'issue_title', 'publish_date', 'issue_description', 'penciler', 'writer', 'comic_id'])\n",
    "df1.fillna(\"\", inplace=True)\n",
    "df1.to_csv('marvel_comics.csv', index=False)\n",
    "df1 = pd.read_csv('marvel_comics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchases DataFrame = df2\n",
    "df2 = pd.DataFrame(purchase_table_query, columns=['purchase_date', 'cust_id', 'comic_id'])\n",
    "df2.to_csv('purchases.csv', index=False)\n",
    "df2 = pd.read_csv('purchases.csv')\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcdf6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df = df.copy() # Copy of original customers dataframe\n",
    "\n",
    "comics_df = pd.DataFrame(marvel_comics_query_3, columns=['comic_name', 'issue_title', 'publish_date', 'penciler', 'writer', 'comic_id'])\n",
    "comics_df.to_csv('comics.csv', index=False)\n",
    "comics_df = pd.read_csv('comics.csv')\n",
    "\n",
    "purch_df = df2.copy() # Copy of original purchases dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152537ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To test that the recommendation system performs adequately, a mock login page was created. This login page takes a username and password and, upon successful login, displays comic recommendations based on the descriptions associated with the customer's last 3 comic book purchases. There are also buttons displayed to view reports (a bar chart visualizing the customer's preferred titles based on most purchased titles and a list of the titles/number of issues of each title the customer has purchased), a network graph (a visualization of the cosine similarities of all titles in the marvelcomics dataframe), and an exit button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db76cee-aec1-4cb5-9978-42bbfc126394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Widgets\n",
    "customer_name_input = widgets.Text(placeholder = 'Enter username') # prompt for customer to enter their username\n",
    "\n",
    "customer_password_input = widgets.Password(placeholder = 'Enter password') # prompt for customer to enter their password\n",
    "\n",
    "login_button = widgets.Button(description='Login', disabled=False, tooltip='Login', width='auto') # login button\n",
    "\n",
    "login_button.style.button_color = 'MediumAquamarine' # login button color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460ba5e-70a7-4844-bc67-30e4a07eaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout for recommendations output\n",
    "output_box_1 = widgets.Output()\n",
    "\n",
    "reports_button = widgets.Button(description='Get Reports', disabled=False)\n",
    "\n",
    "exit_button = widgets.Button(description='Exit', disabled=False)\n",
    "exit_button.style.button_color = 'red'\n",
    "\n",
    "recommendations_page = widgets.HBox([output_box_1, reports_button, exit_button])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce50826-c70d-4b31-a8aa-c43ffaf1cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image\n",
    "image_path = 'C:/Users/exocu/Downloads/HideousMummy.jpg'\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    image_data = base64.b64encode(f.read()).decode()\n",
    "\n",
    "img_tag = f\"<img src='data:image/jpeg;base64, {image_data}'>\"\n",
    "\n",
    "image_html = HTML(img_tag)\n",
    "\n",
    "image_widget = widgets.Output()\n",
    "\n",
    "with image_widget:\n",
    "     display(image_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c2be8-a756-42bc-9d6d-901129450741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout for login\n",
    "vbox_result = widgets.VBox([customer_name_input, customer_password_input, login_button])\n",
    "text_0 = widgets.HTML(value=\"<h1>Hideous Mummy Comics</h1>\")\n",
    "label_headline = widgets.Label(value='', style={'description_width':'initial'}, align_content='center')\n",
    "vbox_headline = widgets.VBox([label_headline])\n",
    "\n",
    "vbox_text = widgets.VBox([text_0, vbox_result])\n",
    "page = widgets.VBox([vbox_headline, vbox_text, image_widget])\n",
    "\n",
    "out = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebf7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get customer id from .txt file\n",
    "with open('customer_id.txt', 'r') as file:\n",
    "    c_id = int(file.readline().strip().replace(\"'\", \"\")) # Change value to int\n",
    "\n",
    "# Compare c_id to cust_id in purchase table to retrieve customer's last 3 purchases\n",
    "df3 = df2[df2['cust_id'] == c_id].sort_values(by='purchase_date', ascending=False)\n",
    "df3.to_csv('df3.csv', index=False)\n",
    "df3 = pd.read_csv('df3.csv')\n",
    "\n",
    "df_last_3 = df3.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from marvelcomics table that matches each comic_id to use for recommendations\n",
    "merged_df = pd.merge(df_last_3, df1[['comic_id', 'issue_title', 'issue_description']], on='comic_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db38b261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add descriptions from merged_df to a list for use with recommendation function\n",
    "last_3_purchase_descrips = merged_df['issue_title'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4cc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Marvel Comics DataFrame #2 (copy) = df4_copied\n",
    "df4 = pd.DataFrame(marvel_comics_table_query, columns=['issue_title', 'publish_date', 'issue_description', 'penciler', 'writer', 'comic_id'])\n",
    "df4.to_csv('df4.csv', index=False)\n",
    "df4 = pd.read_csv('df4.csv', na_values=['null', 'na', 'NA', 'nan', 'NaN'])\n",
    "df4.dropna(inplace=True)\n",
    "\n",
    "df4_copied = df4.copy()\n",
    "#df4_copied['issue_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2448419d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df4_copied.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection and cursor\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c788909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmy = WordNetLemmatizer()\n",
    "\n",
    "# Initilaize the stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1507e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess issue_description text\n",
    "def preprocess_description(text):\n",
    "    text = str(text) # Convert input text to string\n",
    "\n",
    "    text = text.lower() # Convert text to lowercase\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text) # Remove special characters and digits\n",
    "\n",
    "    tokens = nltk.word_tokenize(text) # Divide sentences into terms (tokens)\n",
    "\n",
    "    tokens = [word for word in tokens if word not in stop_words] # Remove the stop words\n",
    "\n",
    "    tokens = [lemmy.lemmatize(word) for word in tokens] # Lemmatize the tokens\n",
    "\n",
    "    return \" \".join(tokens) # Return processed text as a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0366d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess dataframe\n",
    "def preprocess_dataframe(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(preprocess_description)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74885736",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_copied = preprocess_dataframe(df4_copied, 'issue_description')\n",
    "#df4_copied['issue_description'].head(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb650ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, max_df=0.5, stop_words='english') \n",
    "tfidf_matrix = tfidf.fit_transform(df4_copied['issue_description']) # Develop vector matrix for issue_descriptions using fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab5264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972304bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define simlarity threshold\n",
    "min_similarity_threshold = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to batch process the tfidf_matrix using cosine similarity to help with memory usage\n",
    "def batch_cosine_similarity(tfidf_matrix, min_similarity_threshold = 0.25, batch_size=1000):\n",
    "    n_rows = tfidf_matrix.shape[0]\n",
    "    cosine_sim = np.zeros((n_rows, n_rows))\n",
    "\n",
    "    for start in range(0, n_rows, batch_size):\n",
    "        end = min(start + batch_size, n_rows)\n",
    "        batch_sim = linear_kernel(tfidf_matrix[start:end], tfidf_matrix)\n",
    "        cosine_sim[start:end] = batch_sim\n",
    "        \n",
    "        # Apply thresholding to remove values below min_similarity_threshold\n",
    "        cosine_sim[cosine_sim < min_similarity_threshold] = 0.0\n",
    "    \n",
    "    return cosine_sim\n",
    "\n",
    "cosine_sim = batch_cosine_similarity(tfidf_matrix, min_similarity_threshold=min_similarity_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a584e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(df4_copied.index, index=df4_copied['issue_title']).drop_duplicates()\n",
    "#indices[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b028cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take issue_title as input and then output top 3 recommendations \n",
    "# (comics most similar to issue_description mapped to input issue_title)\n",
    "title = df4_copied['issue_title']\n",
    "\n",
    "def get_recommendations(title, cosine_sim=cosine_sim, top_n=3):\n",
    "    if title in indices:\n",
    "        idx = indices[title]\n",
    "        #print(\"Index for title:\", idx) # Comment out\n",
    "        #print(\"Cosine similarities for title:\", cosine_sim[idx]) \n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        #print(\"Enumerated similarity scores:\", sim_scores) \n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        #print(\"Sorted similarity scores:\", sim_scores) \n",
    "        sim_scores = sim_scores[1:top_n + 1]\n",
    "\n",
    "        print(\"Based on your purchase of \"+title+\", you should check out these comics:\\n\")\n",
    "        print(\"\\n\")\n",
    "        for i, score in sim_scores:\n",
    "            description = str(df1['issue_description'].iloc[i])\n",
    "            wrapped_description = textwrap.fill(description, width=50)\n",
    "            formatted_score = '{:.2%}'.format(score) # Format score to read like '45.00%'\n",
    "            print(f\"Title: {df1['issue_title'].iloc[i]}\\n\\nWriter: {df1['writer'].iloc[i]}\\n\\nPenciler: {df1['penciler'].iloc[i]}\\n\\nDescription: {wrapped_description}\\n\\nSimilarity Score: {formatted_score}\\n\")\n",
    "            print(\"\\n\\n\")\n",
    "    else:\n",
    "        logging.error(\"Title not found in index.\")\n",
    "        print(\"Title not found in the index.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test run; Insert any issue from the dataframe into the parentheses as shown\n",
    "#get_recommendations('A Year of Marvels: April Infinite Comic (2016) #1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a6af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define login logic\n",
    "def login(self):      \n",
    "    \n",
    "    try:\n",
    "\n",
    "        login_button.description = 'Attempting Login...'\n",
    "\n",
    "        # Query dataframe to check if user exists/password is correct\n",
    "        # 1) Get input username and password\n",
    "        customer_user_name = customer_name_input.value\n",
    "        customer_password = customer_password_input.value\n",
    "        \n",
    "        # 2) Check inputs against values in dataframe, then grab customer id and name\n",
    "        for index, row in df.iterrows():\n",
    "            if row['username'] == customer_user_name and row['user_pass'] == customer_password:\n",
    "\n",
    "                customer_id = df.loc[df['username'] == customer_user_name, 'cust_id'].iloc[0] # Extract customer id from df result\n",
    "                customer_name = df.loc[df['user_pass'] == customer_password, 'cust_name'].iloc[0] # Extract customer name from df result\n",
    "\n",
    "                login_result = f'Welcome, {customer_name}.'\n",
    "                login_button.layout.width = 'auto'\n",
    "                login_button.description = login_result\n",
    "\n",
    "\n",
    "                if customer_id:\n",
    "\n",
    "                    with open(\"customer_id.txt\", \"w\") as f:\n",
    "                        f.write(str(customer_id)) # Save customer id as string to .txt file\n",
    "\n",
    "                    # Get customer id from .txt file\n",
    "                    with open('customer_id.txt', 'r') as file:\n",
    "                        c_id = int(file.readline().strip().replace(\"'\", \"\")) # Change value to int\n",
    "\n",
    "                    logging.info(\"Succesful login, Customer ID: \" + str(c_id))\n",
    "\n",
    "                    # Compare c_id to cust_id in purchase table to retrieve customer's last 3 purchases\n",
    "                    df3 = df2[df2['cust_id'] == c_id].sort_values(by='purchase_date', ascending=False)\n",
    "\n",
    "                    df_last_3 = df3.head(3)\n",
    "     \n",
    "                    # Get data from marvelcomics table that matches each comic_id to use for recommendations\n",
    "                    merged_df = pd.merge(df_last_3, df1[['comic_id', 'issue_title', 'issue_description']], on='comic_id', how='left')\n",
    "\n",
    "                    # Add descriptions from merged_df to a list for use with recommendation function\n",
    "                    last_3_purchase_descrips = merged_df['issue_title'].to_list()  \n",
    "\n",
    "                    output_box_1.clear_output()\n",
    "\n",
    "                    with output_box_1:\n",
    "                        for title in last_3_purchase_descrips:\n",
    "                            get_recommendations(title)\n",
    "                                       \n",
    "                    display(recommendations_page)\n",
    "                    \n",
    "                else:\n",
    "                    logging.error(\"Invalid username or password or both.\")\n",
    "                    login_result = 'Invalid username or password. Boo! Hiss!'\n",
    "                    login_button.description = login_result\n",
    "                    login_status = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        logging.exception(f\"An error has occurred: {str(e)}\")\n",
    "        print(f\"An error has occurred: {str(e)}\")\n",
    "\n",
    "# Bind login logic to button click)\n",
    "logging.info(\"login_button clicked\")\n",
    "login_button.on_click(login)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a827793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualized data...\n",
    "\n",
    "# Get customer's top 10 favorite (preferred) titles by purchase\n",
    "\n",
    "# Merge dataframes\n",
    "merged_df2 = pd.merge(cust_df, purch_df, on='cust_id')\n",
    "merged_df2 = pd.merge(merged_df2, comics_df, on='comic_id')\n",
    "\n",
    "# Function to handle cases where only single issues of all comic_names purchased by customer are found\n",
    "def get_top_comics(c_id):\n",
    "    customer_data = merged_df2[merged_df2['cust_id'] == c_id]\n",
    "\n",
    "    if customer_data.empty:\n",
    "        logging.error(\"customer_data.empty\")\n",
    "        return None\n",
    "    else:\n",
    "        # Calculate the number of purchases per comic (comic_name) for customer with cust_id\n",
    "        top_comics = customer_data.groupby('comic_name').size().reset_index(name='purchase_count')\n",
    "        #print(top_comics)\n",
    "        top_comics = top_comics.sort_values(by='purchase_count', ascending=False) # Sort by purchase count\n",
    "        \n",
    "        logging.info(\"customer's top_comics values successfully listed\")\n",
    "        return top_comics.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe203bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display bar chart detailing logged-in customer's top 10 preferred \n",
    "# comic titles according to purchase history\n",
    "def display_top_comics_chart(c_id):\n",
    "    \n",
    "    customer_data = merged_df2[merged_df2['cust_id'] == c_id]\n",
    "\n",
    "    if customer_data.empty:\n",
    "        logging.error(\"customer has no purchases\")\n",
    "        print(\"No purchases for this customer.\")\n",
    "    else:\n",
    "        purchase_counts = customer_data['comic_name'].value_counts().reset_index()\n",
    "        purchase_counts.columns = ['comic_name', 'purchase_count']\n",
    "\n",
    "        top_comics_chart = purchase_counts.sort_values(by='purchase_count', ascending=False).head(10)\n",
    "        logging.info(\"Creating bar chart detailing customer's top comics...\")\n",
    "    \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(top_comics_chart['comic_name'], top_comics_chart['purchase_count'], color='skyblue')\n",
    "        plt.xlabel('Number of Issues Purchased per Title')\n",
    "        plt.ylabel('Comic Name')\n",
    "        plt.title(\"Customer's Preferred Comic Book Titles\")\n",
    "        plt.gca().invert_yaxis() # Invert y-axis to show title with most purchases at top\n",
    "        plt.xticks(np.arange(0, top_comics_chart['purchase_count'].max() + 1, 1)) # Ensure only whole purchase values are shown along x-axis \n",
    "        plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define reports button logic\n",
    "\n",
    "def reports(self):\n",
    "\n",
    "    # Get customer id from .txt file\n",
    "    with open('customer_id.txt', 'r') as file:\n",
    "        c_id = int(file.readline().strip().replace(\"'\", \"\")) # Change value to int\n",
    "    # Get customer id from .txt file\n",
    "        display_top_comics_chart(c_id)\n",
    "    #get_customer_top_titles() # Titles purchased recently by customers (10 listed titles is default, but will be less if fewer than 10 purchases exist for customer)\n",
    "    top_comics = get_top_comics(c_id)\n",
    "    if top_comics:\n",
    "        logging.info(\"Printing customer's purchased titles...\")\n",
    "        print(\"Customer's Purchased Titles\")\n",
    "        for comic in top_comics:\n",
    "            print(comic)\n",
    "\n",
    "reports_button.on_click(reports)\n",
    "logging.info(\"reports_button clicked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4863312-3502-4971-b6a6-dfbaf16b193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display network graph showing cosine similarities of all comic book titles in the dataframe\n",
    "def get_network_graph():   \n",
    "    \n",
    "    zip_file_path = 'C:/Users/exocu/Comic_Recommender/network_graph.zip'\n",
    "    \n",
    "    with ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall('extracted_files')\n",
    "        \n",
    "    html_file_path = 'extracted_files/network_graph.html'\n",
    "    \n",
    "    # Display the HTML content in the notebook\n",
    "    display(IFrame(html_file_path, width=1000, height=600))\n",
    "    #display(FileLink(html_file_path))\n",
    "    \n",
    "    \n",
    "    # For opening/displaying the network graph in a new webrowser window\n",
    "    \n",
    "    # Path to the Firefox executable\n",
    "    #firefox_path = \"C:/Program Files/Mozilla Firefox/firefox.exe\"\n",
    "\n",
    "    # Check if Firefox executable exists\n",
    "    #if os.path.exists(firefox_path):\n",
    "        # Specify Firefox as the browser to open the HTML file\n",
    "        #webbrowser.register('firefox', None, webbrowser.BackgroundBrowser(firefox_path))\n",
    "        #webbrowser.get('firefox').open(html_file_path)\n",
    "    \n",
    "    #else:\n",
    "        # Interactive network graph visualizing the proximity of cosine similarities of all titles in the dataset\n",
    "        #logging.info(\"Opening cosine similarities network graph...\")\n",
    "        #webbrowser.open(html_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The client specifically addressed the issue of offloading comic book backstock. The less popular titles and issues continue to take up physical space in the shop, and the recommendation system needs to allow for comics with less similar descriptions to be recommended. \n",
    "\n",
    "#However, a way to recommend comics by similar titles (for use by customers, but more specifically for Hideous Mummy's in-store recommendations) is also available to the client, with greater similarity between input titles and recommendations. There are 2 ways to search for a title: using dropdown menus or a search box. \n",
    "\n",
    "#The dropdown menus produce more accurate recommendations faster, given that the entire selected title is submitted and compared to the titles in the dataframe, as opposed to the search box's input being compared as it is typed, incomplete until the user stops typing. There is also a distinct lag between the finalized recommendations given when using the search box, due to the call to the recommendations_by_search function for each character typed into the search box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd2c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations by title, using 2 dropdowns and output, as well as a search box and output\n",
    "\n",
    "# As implemented, the search box is a less reliable method of getting recommendations,\n",
    "# due to exact title matches being wholly dependent upon user input.\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    return linear_kernel(x, y)\n",
    "\n",
    "# Dropdown to select comic_name for recommendations by comic_name\n",
    "comic_selecter_dropdown = widgets.Dropdown(options=list(comics_df['comic_name'].unique()), description='Comic Title', disabled=False)\n",
    "comic_selecter_dropdown.layout.width = '480px'\n",
    "\n",
    "# Function to filter comic names based on the selected letter\n",
    "def filter_comic_names(letter):\n",
    "    filtered_comics = comics_df[comics_df['comic_name'].str.startswith(letter)]\n",
    "    comic_selecter_dropdown.options = list(filtered_comics['comic_name'].unique())\n",
    "\n",
    "# Create dropdown for selecting the first letter of comic names\n",
    "title_begins_with_dropdown = widgets.Dropdown(options=[chr(i) for i in range(65, 91)], description='Starts With')\n",
    "title_begins_with_dropdown.layout.width = '480px'\n",
    "\n",
    "# Function to handle changes in title_begins_with_dropdown\n",
    "def handle_letter_change(change):\n",
    "    if change.new is not None:\n",
    "        filter_comic_names(change.new)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "title_begins_with_dropdown.observe(handle_letter_change, names='value')\n",
    "\n",
    "def handle_dropdown_change(comic_title):\n",
    "    print(f\"Selected Comic Title: {comic_title}\")\n",
    "\n",
    "filter_comic_names('A')\n",
    "\n",
    "# Modify TF-IDF and Cosine Similarity to use comic_name rather than issue_description\n",
    "tfidf_vectorizer2 = TfidfVectorizer(min_df=5, max_df=0.5, stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer2.fit_transform(comics_df['comic_name'])\n",
    "\n",
    "# Define similarity threshold\n",
    "min_similarity_threshold = 0.05\n",
    "\n",
    "# Function to get recommendations by comic_name (The comic book's title)\n",
    "def get_title_recs(comic_title, tfidf_matrix=tfidf_matrix, min_similarity=min_similarity_threshold):\n",
    "\n",
    "    comic_tfidf = tfidf_vectorizer2.transform([comic_title])\n",
    "    \n",
    "    cosine_similarities = cosine_similarity(comic_tfidf, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Filter out similarities below minimum threshold\n",
    "    similar_indices = [i for i, score in enumerate(cosine_similarities) if score >= min_similarity]\n",
    "    \n",
    "    recommended_titles = comics_df.iloc[similar_indices]['comic_name'].tolist()\n",
    "\n",
    "    return recommended_titles\n",
    "\n",
    "output_title_recommendations = widgets.Output()\n",
    "\n",
    "# Function to ensure unique recommendations and eliminate the selected comic as a recommended comic\n",
    "def get_unique_recs(selected_comic, num_recommendations):\n",
    "    # Get index of selected comic\n",
    "    selected_index = comics_df[comics_df['comic_name'] == selected_comic].index[0]\n",
    "\n",
    "    # Calculate cosine similarity scores\n",
    "    cosine_similarity_scores = cosine_similarity(tfidf_matrix[selected_index:selected_index+1], tfidf_matrix).flatten()\n",
    "\n",
    "    # Sort indices based on similarity scores\n",
    "    sim_scores_sorted_indices = cosine_similarity_scores.argsort()[::-1]\n",
    "\n",
    "    # Initialize a list to store unique recommendations\n",
    "    unique_recs = []\n",
    "        \n",
    "    # Iterate over sorted indices\n",
    "    for index in sim_scores_sorted_indices:\n",
    "        comic_name = comics_df.iloc[index]['comic_name']\n",
    "            \n",
    "        # Skip the selected comic and any duplicate recommendations\n",
    "        if comic_name != selected_comic and comic_name not in unique_recs:\n",
    "            unique_recs.append(comic_name)\n",
    "\n",
    "        # Break if desired number of recommendations is reached    \n",
    "        if len(unique_recs) >= num_recommendations:\n",
    "            break\n",
    "\n",
    "    return unique_recs\n",
    "\n",
    "# Function to update output widget with recommended titles\n",
    "def update_title_recs(change):\n",
    "    global recommendations\n",
    "    selected_comic = change.new\n",
    "    if selected_comic:    \n",
    "        recommendations = get_unique_recs(selected_comic, 5)\n",
    "\n",
    "        with output_title_recommendations:\n",
    "            output_title_recommendations.clear_output()\n",
    "            logging.info(\"Printing recommendations (via dropdowns)...\")\n",
    "            print(\"Based on your selection, you should check out these titles:\")\n",
    "            print()\n",
    "            for comic in recommendations[:5]:\n",
    "                print(comic)\n",
    "\n",
    "comic_selecter_dropdown.observe(update_title_recs, names='value')\n",
    "\n",
    "# Function to clear selections in both dropdowns\n",
    "def clear_dropdown_selections():\n",
    "    comic_selecter_dropdown.value = None\n",
    "    title_begins_with_dropdown.value = None\n",
    "\n",
    "# Get recommendation using search function\n",
    "search_box = widgets.Text(description='Search', disabled=False)\n",
    "search_box.layout.width='480px'\n",
    "\n",
    "# Function to get recommendations by comparing string input to titles in dataframe\n",
    "def recommendations_by_search(change):\n",
    "    search_query = change.new\n",
    "    if search_query is not None:\n",
    "        clear_dropdown_selections()\n",
    "        filtered_comics_df = comics_df[comics_df['comic_name'].str.contains(search_query, case=False)]      \n",
    "\n",
    "        unique_recommendations = set()\n",
    "        if not filtered_comics_df.empty:\n",
    "            # Pre-compute TF-IDF vectors for all comic names\n",
    "            comic_tfidf_matrix = tfidf_vectorizer2.transform(filtered_comics_df['comic_name'])\n",
    "            \n",
    "            for comic_tfidf in comic_tfidf_matrix:\n",
    "                # Calculate cosine similarities with all TF-IDF vectors\n",
    "                cosine_similarities = cosine_similarity(comic_tfidf, tfidf_matrix).flatten()\n",
    "                similar_indices = cosine_similarities.argsort()[:-6:-1]\n",
    "                recommended_titles = comics_df.iloc[similar_indices]['comic_name'].tolist()\n",
    "                unique_recommendations.update(recommended_titles[:5])\n",
    "\n",
    "        with output_title_recommendations:\n",
    "            output_title_recommendations.clear_output()\n",
    "            logging.info(\"Printing recommendations (via search_box)...\")\n",
    "            print(\"Based on your search, you should check out these titles:\")\n",
    "            print()\n",
    "            for title in list(unique_recommendations)[:5]:\n",
    "                print(title)\n",
    "    \n",
    "    else:\n",
    "        with output_title_recommendations:\n",
    "            output_title_recommendations.clear_output()\n",
    "            print(\"Search for a title to get recommendations.\")            \n",
    "\n",
    "search_box.observe(recommendations_by_search, names='value')\n",
    "\n",
    "# Function to update selected_comic_title\n",
    "def update_selected_comic_title(change):\n",
    "    global selected_comic_title\n",
    "    selected_comic_title = change.new\n",
    "    search_box.value = '' # Clear search_box when dropdown is used\n",
    "\n",
    "# Observe changes in comic_selecter_dropdown and search_box\n",
    "comic_selecter_dropdown.observe(update_selected_comic_title, names='value')\n",
    "search_box.observe(update_selected_comic_title, names='value')\n",
    "\n",
    "# Function to handle title_begins_with dropdown\n",
    "def secondary_letter_change_handler(change):\n",
    "    if change.new is not None:\n",
    "        filter_comic_names(change.new)\n",
    "        search_box.value = '' # Clear search_box when begins_with_dropdown is used\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "title_begins_with_dropdown.observe(secondary_letter_change_handler, names='value')\n",
    "\n",
    "rec_similarities_scatterplot_button = widgets.Button(description='Recommendation Similarities Scatterplot', disabled=False)\n",
    "rec_similarities_scatterplot_button.layout.width = 'auto'\n",
    "\n",
    "#VBox for dropdowns\n",
    "dropdowns_box = widgets.VBox([title_begins_with_dropdown])\n",
    "\n",
    "# VBox for search_box and search_box's ouput widget\n",
    "search_v_box = widgets.VBox([search_box, output_title_recommendations])\n",
    "\n",
    "# HBox to hold dropdowns, search_box, and search_box's output widget\n",
    "inputs_box = widgets.HBox([dropdowns_box, search_v_box])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An interactive scatterplot is created and opened in a new browser window when a button is clicked, and displays points for the selected title and its group of recommendations. Hovering over a plotted point will display the comic's title and the cosine similarity score of that title in relation to the title selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3165947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variable to set selected comic title\n",
    "selected_comic_title = None\n",
    "\n",
    "# Function to create scatterplot\n",
    "def create_scatterplot():\n",
    "    \n",
    "    global selected_comic_title, recommendations    \n",
    "    \n",
    "    # Check if selected_comic_title is set\n",
    "    if selected_comic_title is not None:\n",
    "        logging.info(\"Creating scatterplot...\")\n",
    "        # Calculate cosine similarities for selected comic title\n",
    "        comic_tfidf = tfidf_vectorizer2.transform([selected_comic_title])\n",
    "        cosine_similarities = cosine_similarity(comic_tfidf, tfidf_matrix).flatten()\n",
    "\n",
    "        # Get indices of top most similar comics\n",
    "        top_indices = cosine_similarities.argsort()[:-101:-1]\n",
    "        if len(top_indices) < 100:\n",
    "            top_indices = cosine_similarities.argsort()[:-len(top_indices)-1:-1]\n",
    "\n",
    "        # Get titles and similarities of top most similar comics\n",
    "        similar_comics = comics_df.iloc[top_indices]\n",
    "        similar_titles = similar_comics['comic_name']\n",
    "        similarities = cosine_similarities[top_indices]\n",
    "\n",
    "        # Ensure inclusion of recommended comics with selected comic\n",
    "        recommended_indices = [comics_df[comics_df['comic_name'] == comic].index[0] for comic in recommendations]\n",
    "        similar_comics_recs = comics_df.iloc[recommended_indices]\n",
    "        similar_titles_recs = similar_comics_recs['comic_name']\n",
    "        similarities_recs = [1.0] * len(recommendations) # Similarity set to 1 for recommended comics\n",
    "\n",
    "        # Combine titles and similarities for scatterplot\n",
    "        combined_titles = pd.concat([similar_titles, similar_titles_recs], ignore_index=True)\n",
    "        combined_similarities = np.concatenate([similarities, similarities_recs])\n",
    "        \n",
    "        # Hover text with titles and cosine similarity scores\n",
    "        hover_text = [f'{title}: {sim:.2f}' for title, sim in zip(combined_titles, combined_similarities)]\n",
    "        \n",
    "\n",
    "        # Create scatterplot data\n",
    "        scatter_data = go.Scatter(\n",
    "            x=combined_titles,\n",
    "            y=combined_similarities,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=10,\n",
    "                color=combined_similarities,\n",
    "                colorscale='Viridis',\n",
    "                showscale=True,\n",
    "                colorbar=dict(\n",
    "                    title='Cosine Similarity<br>&nbsp;',\n",
    "                    titleside='right'\n",
    "                ),\n",
    "            ),\n",
    "            text=hover_text,\n",
    "            hoverinfo='text'\n",
    "         )\n",
    "        \n",
    "        # Create lines to connect plot points\n",
    "        line_data = []\n",
    "        for i in range(len(similar_titles)):\n",
    "            line_data.append(go.Scatter(\n",
    "            x=[selected_comic_title, similar_titles.iloc[i]],\n",
    "            y=[1.0, similarities[i]],\n",
    "            mode='lines',\n",
    "            hoverinfo='text',\n",
    "            line=dict(\n",
    "                color='gray',\n",
    "                width=1\n",
    "            ),\n",
    "            showlegend=False\n",
    "            ))\n",
    "\n",
    "        # Create layout for scatterplot\n",
    "        layout = go.Layout(\n",
    "            title=f\"Top Similar Comics for {selected_comic_title}\",\n",
    "            xaxis=dict(title=\"Comic Title\"),\n",
    "            yaxis=dict(title=\"Cosine Similarity\"),\n",
    "            width=1600,\n",
    "            height=800\n",
    "        )\n",
    "\n",
    "        # Create figure and plot scatterplot\n",
    "        fig = go.Figure(data=[scatter_data, *line_data], layout=layout)\n",
    "        \n",
    "        # Clear any previously generated scatterplots\n",
    "        fig.data = []\n",
    "        \n",
    "        fig.add_trace(scatter_data)\n",
    "        for line in line_data:\n",
    "            fig.add_trace(line)\n",
    "        \n",
    "        fig.update_layout(yaxis={'categoryorder':'total ascending'})\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"Select a comic title.\")\n",
    "\n",
    "# Function to update selected comic title\n",
    "def update_selected_comic_title(change):\n",
    "    global selected_comic_title\n",
    "    selected_comic_title =  change.new\n",
    "\n",
    "# Observe changes in comic_selecter_dropdown and search_box\n",
    "comic_selecter_dropdown.observe(update_selected_comic_title, names='value')\n",
    "search_box.observe(update_selected_comic_title, names='value')\n",
    "\n",
    "# Bind to button\n",
    "rec_similarities_scatterplot_button.on_click(lambda _:create_scatterplot())\n",
    "logging.info(\"rec_similarities_scatterplot_button clicked\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce948602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create network graph visualizing cosine similarities of all titles in the dataframe\n",
    "# Commented out because it takes a long time to run and doesn't need to be run more than once.\n",
    "\n",
    "#df5 = comics_df.copy()\n",
    "#df5 = preprocess_dataframe(df5, 'comic_name')\n",
    "\n",
    "#tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#tfidf_matrix = tfidf_vectorizer.fit_transform(df5['comic_name'])\n",
    "#cosine_similarity_matrix = batch_cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Create the network graph\n",
    "#def create_network_graph():\n",
    "    # Define labels and edges for the graph\n",
    "    #labels = list(df5['comic_name'])\n",
    "    #edge_x = []\n",
    "    #edge_y = []\n",
    "    #weights = []\n",
    "\n",
    "    # Create graph edges\n",
    "    #for i in range(len(comics_df)):\n",
    "        #for j in range(i+1, len(df5)):\n",
    "            #if cosine_similarity_matrix[i, j] > 0.5:  # Adjust threshold as needed\n",
    "                #edge_x.append(labels[i])\n",
    "                #edge_y.append(labels[j])\n",
    "                #weights.append(cosine_similarity_matrix[i, j])\n",
    "\n",
    "    # Create edge trace\n",
    "    #edge_trace = go.Scatter(\n",
    "        #x=edge_x,\n",
    "        #y=edge_y,\n",
    "        #line=dict(width=0.5, color='#888'),\n",
    "        #hoverinfo='none',\n",
    "        #mode='lines'\n",
    "    #)\n",
    "\n",
    "    # Create node trace\n",
    "    #node_trace = go.Scatter(\n",
    "        #x=labels,\n",
    "        #y=labels,\n",
    "        #mode='markers',\n",
    "        #hoverinfo='text',\n",
    "        #marker=dict(\n",
    "            #showscale=False,\n",
    "            #colorscale='Viridis',\n",
    "            #reversescale=True,\n",
    "            #color=[],\n",
    "            #size=10,\n",
    "            #colorbar=dict(\n",
    "                #thickness=15,\n",
    "                #title='Node Connections',\n",
    "                #xanchor='left',\n",
    "                #titleside='right'\n",
    "            #),\n",
    "            #line_width=2\n",
    "        #)\n",
    "    #)\n",
    "\n",
    "    # Add node labels\n",
    "    #node_trace.text = labels\n",
    "\n",
    "    # Create figure and plot the graph\n",
    "    #fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                    #layout=go.Layout(\n",
    "                        #title='<br>Network graph of comic title similarities',\n",
    "                        #titlefont_size=16,\n",
    "                        #showlegend=False,\n",
    "                        #hovermode='closest',\n",
    "                        #margin=dict(b=20, l=5, r=5, t=40),\n",
    "                        #annotations=[dict(\n",
    "                            #showarrow=False,\n",
    "                            #xref=\"paper\", yref=\"paper\",\n",
    "                            #x=0.005, y=-0.002\n",
    "                        #)],\n",
    "                        #xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        #yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    "                     #)\n",
    "                    #)\n",
    "\n",
    "    #  Save as interactive HTML graph\n",
    "    #fig.write_html(\"network_graph.html\")\n",
    "    #display(HTML(filename='network_graph.html'))\n",
    "    # Show plot\n",
    "    #fig.show()\n",
    "#cos_sim_graph_button.on_click(lambda _:create_network_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db92c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define exit button logic\n",
    "\n",
    "def exit(self):\n",
    "\n",
    "    clear_output()\n",
    "    display(page)\n",
    "    customer_name_input.value = \"\"\n",
    "    customer_password_input.value = \"\"\n",
    "    login_button.description = \"Login\"\n",
    "    login_button.width = \"auto\"\n",
    "\n",
    "exit_button.on_click(exit)\n",
    "logging.info(\"exit_button clicked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display\n",
    "display(page)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3dae95",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(inputs_box)\n",
    "interact(handle_dropdown_change, comic_title=comic_selecter_dropdown)\n",
    "display(rec_similarities_scatterplot_button)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New dataframe using only descriptions for wordcloud generation\n",
    "df_descriptions = df4_copied['issue_description'].copy()\n",
    "\n",
    "# Initialize vectorizer and fit /transform data\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(df_descriptions)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Calculate TF-IDF average scores for each word\n",
    "tfidf_scores = vectors.mean(axis=0).A1\n",
    "\n",
    "# Map words to TF-IDF scores\n",
    "tfidf_dict = dict(zip(feature_names, tfidf_scores))\n",
    "\n",
    "# Verify highest_scored words are largest in wordcloud\n",
    "tfidf_sorted = sorted(tfidf_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "# Generate the wordcloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(tfidf_dict)\n",
    "\n",
    "# Plot the wordcloud\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"\")\n",
    "tfidf_formatted = [f\"{word}: {score:.4f}\" for word, score in tfidf_sorted]\n",
    "print(\"Top words by TF-IDF score:\")\n",
    "for item in tfidf_formatted[:30]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_network_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
